{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14180\\4191208872.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables de configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.metacritic.com'\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"enable-automation\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--dns-prefetch-disable\")\n",
    "options.add_argument(\"--disable-gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_basic_game_information(url):\n",
    "    details_url = f'{BASE_URL}{url}details/'\n",
    "    response = requests.get(details_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    game_name = soup.find('a', class_=\"c-productSubpageHeader_back\").text.strip()\n",
    "    game_description = soup.find('div', class_=\"c-pageProductDetails_description\").text.strip()\n",
    "    game_developer = soup.find('div', class_=\"c-gameDetails_Developer\").find('li', class_=\"c-gameDetails_listItem\").text.strip()\n",
    "    game_genre = soup.find('li', class_=\"c-genreList_item\").text.strip()\n",
    "\n",
    "    return game_name, game_description, game_developer, game_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(url, review_endpoint, score_type, review_type):\n",
    "    reviews_url = f'{BASE_URL}{url}{review_endpoint}/'\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(120)\n",
    "    driver.get(reviews_url)\n",
    "    page_content = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    reviews = []\n",
    "    review_elements = soup.find_all('div', class_='c-siteReview_main')\n",
    "    for review in review_elements:\n",
    "        score = review.find('div', class_='c-siteReviewScore').text.strip()\n",
    "        review_text = review.find('div', class_='c-siteReview_quote').text.strip()\n",
    "        reviews.append({score_type: score, review_type: review_text})\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_user_reviews(url):\n",
    "    return scrape_reviews(url=url, review_endpoint='user-reviews', score_type='user_score', review_type='user_review_text')\n",
    "\n",
    "def scrape_critic_reviews(url):\n",
    "    return scrape_reviews(url=url, review_endpoint='critic-reviews', score_type='critic_score', review_type='critic_review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_game_data(url):\n",
    "    game_name, game_description, game_developer, game_genre = scrape_basic_game_information(url=url)\n",
    "    user_reviews = scrape_user_reviews(url=url)\n",
    "    critic_reviews = scrape_critic_reviews(url=url)\n",
    "\n",
    "    return {\n",
    "        'Game_name': game_name,\n",
    "        'Game_description': game_description.replace(\"Description:\\n\", \"\").strip(),\n",
    "        'Game_developer': game_developer,\n",
    "        'Game_genre': game_genre,\n",
    "        'User_reviews': user_reviews,\n",
    "        'Critic_reviews': critic_reviews,\n",
    "        'Link': url\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_previous_data(filename):\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        print(f\"Cargando los datos guardados del archivo {filename}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"No se encontró un archivo CSV. Se creará uno nuevo.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_data(scraped_games):\n",
    "    extended_data = []\n",
    "    for game in scraped_games:\n",
    "        number_of_reviews = min(len(game['User_reviews']), len(game['Critic_reviews']))\n",
    "        for i in range(number_of_reviews):\n",
    "            extended_data.append({\n",
    "                'Game_name': game['Game_name'],\n",
    "                'Game_description': game['Game_description'],\n",
    "                'Game_developer': game['Game_developer'],\n",
    "                'Game_genre': game['Game_genre'],\n",
    "                'User_score': game['User_reviews'][i]['user_score'],\n",
    "                'User_review_text': game['User_reviews'][i]['user_review_text'],\n",
    "                'Critic_score': game['Critic_reviews'][i]['critic_score'],\n",
    "                'Critic_review_text': game['Critic_reviews'][i]['critic_review_text'],\n",
    "                'Link': game['Link']\n",
    "            })\n",
    "    return extended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los datos guardados del archivo metacritic_data.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'toList'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14180\\2328276927.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmetacritic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_previous_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'metacritic_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscraped_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmetacritic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mscraped_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetacritic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Link'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlinks_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'game_links.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mrandom_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinks_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'game_links'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\metacritic-scraper\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6289\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6290\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6291\u001b[0m         ):\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'toList'"
     ]
    }
   ],
   "source": [
    "metacritic_df = load_previous_data('metacritic_data.csv')\n",
    "\n",
    "scraped_links = []\n",
    "if not metacritic_df.empty:\n",
    "    scraped_links = metacritic_df['Link'].tolist()\n",
    "\n",
    "links_df = pd.read_csv('game_links.csv')\n",
    "random_links = links_df['game_links']\n",
    "random.shuffle(random_links)\n",
    "\n",
    "scraped_games = []\n",
    "\n",
    "for link in random_links:\n",
    "    if link in scraped_links:\n",
    "        print(f\"El juego con la URL {link} ya ha sido recorrido. Saltando al siguiente.\")\n",
    "        continue\n",
    "    try:\n",
    "        game_data = scrape_game_data(url=link)\n",
    "        scraped_games.append(game_data)\n",
    "        print(f\"Datos del juego {game_data['Game_name']} extraídos correctamente.\")\n",
    "        extended_data = get_extended_data(scraped_games=scraped_games)\n",
    "        scraped_games_df = pd.DataFrame(extended_data)\n",
    "        metacritic_df = pd.concat([metacritic_df, scraped_games_df], ignore_index=True)\n",
    "\n",
    "        metacritic_df.to_csv('metacritic_data.csv', index=False)\n",
    "        print(\"Los datos se han guardado correctamente en metacritic_data.csv\")\n",
    "    except:\n",
    "        print(f\"No se pudo obtener la información del juego con la URL {link}. Saltando al siguiente.\")\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
